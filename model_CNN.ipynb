{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/kfold/baseline-cnn-mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import *\n",
    "DATA_ADDRESS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 640\n",
    "\n",
    "# Architecture\n",
    "num_classes = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = DATA_ADDRESS+\"VOiCES_devkit/\"\n",
    "TRAIN_DIR = DATA_ADDRESS+'preprocessed/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(train_files):\n",
    "    ls_X_trian = []\n",
    "    for train_file in tqdm(train_files):\n",
    "        file_dir = os.path.join(TRAIN_DIR, train_file)\n",
    "        ls_X_trian.append(load_pickle(file_dir))\n",
    "    return np.concatenate(ls_X_trian, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mel_len15_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_12500-12799.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'mel_len15_fft2048_mels128_mfcc17_9500-9999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_12500-12999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_13000-13499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_13500-13999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_14000-14499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_14500-14999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_15000-15499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_15500-15999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_16000-16499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_16500-16999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_17000-17499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_17500-17999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_18000-18499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_18500-18999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_19000-19499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_19500-19999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_20000-20499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_20500-20999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_21000-21499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_21500-21999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_22000-22499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_22500-22999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_23000-23499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_23500-23999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_24000-24499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_24500-24999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_25000-25499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_25500-25999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_26000-26499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_26500-26999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_27000-27499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_27500-27999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_28000-28499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_28500-28999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_29000-29499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_29500-29999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_30000-30499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_30500-30999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_31000-31499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_31500-31999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_32000-32499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_32500-32999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_33000-33499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_33500-33999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_34000-34499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_34500-34999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_35000-35499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_35500-35999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_36000-36499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_36500-36999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_37000-37499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_37500-37999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_38000-38499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_38500-38999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_39000-39499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_39500-39999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_40000-40499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_40500-40999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_41000-41499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_41500-41999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_42000-42499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_42500-42999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_43000-43499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_43500-43999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_44000-44499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_44500-44999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_45000-45499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_45500-45999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_46000-46499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_46500-46999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_47000-47499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_47500-47999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_48000-48499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_48500-48999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_49000-49499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_49500-49663.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'mel_len5_fft2048_mels128_mfcc17_9500-9999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_12500-12799.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'mfcc_len15_fft2048_mels128_mfcc17_9500-9999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_12500-12999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_13000-13499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_13500-13999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_14000-14499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_14500-14999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_15000-15499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_15500-15999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_16000-16499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_16500-16999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_17000-17499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_17500-17999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_18000-18499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_18500-18999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_19000-19499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_19500-19999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_20000-20499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_20500-20999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_21000-21499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_21500-21999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_22000-22499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_22500-22999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_23000-23499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_23500-23999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_24000-24499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_24500-24999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_25000-25499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_25500-25999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_26000-26499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_26500-26999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_27000-27499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_27500-27999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_28000-28499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_28500-28999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_29000-29499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_29500-29999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_30000-30499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_30500-30999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_31000-31499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_31500-31999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_32000-32499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_32500-32999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_33000-33499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_33500-33999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_34000-34499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_34500-34999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_35000-35499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_35500-35999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_36000-36499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_36500-36999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_37000-37499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_37500-37999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_38000-38499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_38500-38999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_39000-39499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_39500-39999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_40000-40499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_40500-40999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_41000-41499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_41500-41999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_42000-42499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_42500-42999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_43000-43499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_43500-43999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_44000-44499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_44500-44999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_45000-45499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_45500-45999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_46000-46499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_46500-46999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_47000-47499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_47500-47999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_48000-48499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_48500-48999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_49000-49499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_49500-49663.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_9500-9999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_12500-12799.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'spectrogram_len15_fft2048_mels128_mfcc17_9500-9999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_12500-12999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_13000-13499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_13500-13999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_14000-14499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_14500-14999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_15000-15499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_15500-15999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_16000-16499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_16500-16999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_17000-17499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_17500-17999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_18000-18499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_18500-18999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_19000-19499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_19500-19999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_20000-20499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_20500-20999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_21000-21499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_21500-21999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_22000-22499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_22500-22999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_23000-23499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_23500-23999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_24000-24499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_24500-24999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_25000-25499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_25500-25999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_26000-26499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_26500-26999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_27000-27499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_27500-27999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_28000-28499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_28500-28999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_29000-29499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_29500-29999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_30000-30499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_30500-30999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_31000-31499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_31500-31999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_32000-32499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_32500-32999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_33000-33499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_33500-33999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_34000-34499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_34500-34999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_35000-35499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_35500-35999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_36000-36499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_36500-36999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_37000-37499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_37500-37999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_38000-38499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_38500-38999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_39000-39499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_39500-39999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_40000-40499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_40500-40999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_41000-41499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_41500-41999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_42000-42499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_42500-42999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_43000-43499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_43500-43999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_44000-44499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_44500-44999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_45000-45499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_45500-45999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_46000-46499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_46500-46999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_47000-47499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_47500-47999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_48000-48499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_48500-48999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_49000-49499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_49500-49663.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'spectrogram_len5_fft2048_mels128_mfcc17_9500-9999.pkl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_prefix = 'mfcc_len5_fft2048_mels128_mfcc17_'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(TRAIN_DIR)\n",
    "pprint(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mfcc_len5_fft2048_mels128_mfcc17_0-499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_1000-1499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_10000-10499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_10500-10999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_11000-11499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_11500-11999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_12000-12499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_12500-12999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_13000-13499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_13500-13999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_14000-14499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_14500-14999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_1500-1999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_15000-15499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_15500-15999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_16000-16499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_16500-16999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_17000-17499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_17500-17999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_18000-18499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_18500-18999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_19000-19499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_19500-19999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_2000-2499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_20000-20499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_20500-20999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_21000-21499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_21500-21999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_22000-22499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_22500-22999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_23000-23499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_23500-23999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_24000-24499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_24500-24999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_2500-2999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_25000-25499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_25500-25999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_26000-26499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_26500-26999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_27000-27499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_27500-27999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_28000-28499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_28500-28999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_29000-29499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_29500-29999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_3000-3499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_30000-30499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_30500-30999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_31000-31499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_31500-31999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_32000-32499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_32500-32999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_33000-33499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_33500-33999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_34000-34499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_34500-34999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_3500-3999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_35000-35499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_35500-35999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_36000-36499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_36500-36999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_37000-37499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_37500-37999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_38000-38499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_38500-38999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_39000-39499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_39500-39999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_4000-4499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_40000-40499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_40500-40999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_41000-41499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_41500-41999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_42000-42499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_42500-42999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_43000-43499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_43500-43999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_44000-44499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_44500-44999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_4500-4999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_45000-45499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_45500-45999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_46000-46499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_46500-46999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_47000-47499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_47500-47999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_48000-48499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_48500-48999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_49000-49499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_49500-49663.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_500-999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_5000-5499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_5500-5999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_6000-6499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_6500-6999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_7000-7499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_7500-7999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_8000-8499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_8500-8999.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_9000-9499.pkl',\n",
      " 'mfcc_len5_fft2048_mels128_mfcc17_9500-9999.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Filter files that start with the specified prefix\n",
    "train_files_mfcc = [file for file in files if file.startswith(file_prefix)]\n",
    "pprint(train_files_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 385.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49664, 17, 216)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_train(train_files_mfcc)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_folder</th>\n",
       "      <th>speaker</th>\n",
       "      <th>distractor</th>\n",
       "      <th>room</th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distant-16k/speech/test/rm2/musi/sp6643</td>\n",
       "      <td>6643</td>\n",
       "      <td>musi</td>\n",
       "      <td>rm2</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distant-16k/speech/test/rm2/musi/sp6643</td>\n",
       "      <td>6643</td>\n",
       "      <td>musi</td>\n",
       "      <td>rm2</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distant-16k/speech/test/rm2/musi/sp6643</td>\n",
       "      <td>6643</td>\n",
       "      <td>musi</td>\n",
       "      <td>rm2</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distant-16k/speech/test/rm2/musi/sp6643</td>\n",
       "      <td>6643</td>\n",
       "      <td>musi</td>\n",
       "      <td>rm2</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distant-16k/speech/test/rm2/musi/sp6643</td>\n",
       "      <td>6643</td>\n",
       "      <td>musi</td>\n",
       "      <td>rm2</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74459</th>\n",
       "      <td>distant-16k/speech/test/rm3/tele/sp0166</td>\n",
       "      <td>0166</td>\n",
       "      <td>tele</td>\n",
       "      <td>rm3</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74460</th>\n",
       "      <td>distant-16k/speech/test/rm3/tele/sp0166</td>\n",
       "      <td>0166</td>\n",
       "      <td>tele</td>\n",
       "      <td>rm3</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74461</th>\n",
       "      <td>distant-16k/speech/test/rm3/tele/sp0166</td>\n",
       "      <td>0166</td>\n",
       "      <td>tele</td>\n",
       "      <td>rm3</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74462</th>\n",
       "      <td>distant-16k/speech/test/rm3/tele/sp0166</td>\n",
       "      <td>0166</td>\n",
       "      <td>tele</td>\n",
       "      <td>rm3</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74463</th>\n",
       "      <td>distant-16k/speech/test/rm3/tele/sp0166</td>\n",
       "      <td>0166</td>\n",
       "      <td>tele</td>\n",
       "      <td>rm3</td>\n",
       "      <td>test</td>\n",
       "      <td>5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74464 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 origin_folder speaker distractor room  \\\n",
       "0      distant-16k/speech/test/rm2/musi/sp6643    6643       musi  rm2   \n",
       "1      distant-16k/speech/test/rm2/musi/sp6643    6643       musi  rm2   \n",
       "2      distant-16k/speech/test/rm2/musi/sp6643    6643       musi  rm2   \n",
       "3      distant-16k/speech/test/rm2/musi/sp6643    6643       musi  rm2   \n",
       "4      distant-16k/speech/test/rm2/musi/sp6643    6643       musi  rm2   \n",
       "...                                        ...     ...        ...  ...   \n",
       "74459  distant-16k/speech/test/rm3/tele/sp0166    0166       tele  rm3   \n",
       "74460  distant-16k/speech/test/rm3/tele/sp0166    0166       tele  rm3   \n",
       "74461  distant-16k/speech/test/rm3/tele/sp0166    0166       tele  rm3   \n",
       "74462  distant-16k/speech/test/rm3/tele/sp0166    0166       tele  rm3   \n",
       "74463  distant-16k/speech/test/rm3/tele/sp0166    0166       tele  rm3   \n",
       "\n",
       "      category                                           filename  \n",
       "0         test  5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...  \n",
       "1         test  5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...  \n",
       "2         test  5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...  \n",
       "3         test  5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...  \n",
       "4         test  5seconds-16k/speech/test/rm2/musi/sp6643/Lab41...  \n",
       "...        ...                                                ...  \n",
       "74459     test  5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...  \n",
       "74460     test  5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...  \n",
       "74461     test  5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...  \n",
       "74462     test  5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...  \n",
       "74463     test  5seconds-16k/speech/test/rm3/tele/sp0166/Lab41...  \n",
       "\n",
       "[74464 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(DATA_ADDRESS+\"df_5s.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1961, 1961, 1961, ..., 1536, 1536, 1536])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df[df['category']=='train']['speaker']).astype('float32')\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load to dataloader from numpy array:\n",
    "\n",
    "https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape torch.Size([49664, 1, 17, 216])\n",
      "y shape torch.Size([49664])\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.Tensor(X) # transform to torch tensor\n",
    "tensor_x = tensor_x.unsqueeze(1) # Add a channel dimension\n",
    "tensor_y = torch.Tensor(y)\n",
    "print(\"X shape\",tensor_x.shape)\n",
    "print(\"y shape\",tensor_y.shape)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x,tensor_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and valid datasets\n",
    "train_dataset, valid_dataset = random_split(train_dataset, lengths=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x122926e4040>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = train_features[200].squeeze()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=8,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                padding=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=8,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                padding=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(784, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                padding=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                padding=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(64 * (17 // 4) * (216 // 4), 1028),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1028, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = PyTorchCNN(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated\n",
    "\n",
    "class PyTorchCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PyTorchCNN, self).__init__()\n",
    "        \n",
    "        # Assuming input size is (batch_size, 1, 17, 216), if not, adjust accordingly.\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Calculate the size of the flattened features after the pooling layers\n",
    "        # Here we assume two pooling layers, so the spatial dimensions are reduced by a factor of 4\n",
    "        self.num_flattened = 64 * (17 // 4) * (216 // 4)\n",
    "        # self.num_flattened = 64 * 17 * 216\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.num_flattened, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        # self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(-1, self.num_flattened)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = PyTorchCNN(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for features, targets in data_loader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float() / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m### Backward pass (backpropagation)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m### Update model parameters\u001b[39;00m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m     (inputs,)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:127\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         )\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    126\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 127\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        targets = targets.type(torch.LongTensor)\n",
    "\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "        ### Forward pass\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        ### Backward pass (backpropagation)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ### Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Batch-level logging\n",
    "        if not (batch_idx + 1) % 100:\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1:03d}/{num_epochs:03d} | \"\n",
    "                f\"Batch: {batch_idx + 1:03d}/{len(train_loader):03d} | \"\n",
    "                f\"Loss: {loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    ### Epoch-level logging\n",
    "    model = model.eval()\n",
    "    train_acc = compute_accuracy(model, train_loader, device)\n",
    "    valid_acc = compute_accuracy(model, valid_loader, device)\n",
    "    print(\n",
    "        f\"Training accuracy: {train_acc * 100:.2f}% | \"\n",
    "        f\"Validation accuracy: {valid_acc * 100:.2f}%\"\n",
    "    )\n",
    "    print(f\"Time elapsed: {(time.time() - start_time) / 60:.2f} min\")\n",
    "\n",
    "print(f\"Total training time: {(time.time() - start_time) / 60:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear gradients from the previous step\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:244\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    235\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m     (inputs,)\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    241\u001b[0m )\n\u001b[0;32m    243\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 244\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32md:\\001Drexel\\12_DSCI_Capstone\\DSCI_Capstone\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:127\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         )\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    126\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 127\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## genereated\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# ... (previous code)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to compute accuracy\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for features, targets in data_loader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float() / num_examples * 100\n",
    "\n",
    "# Training loop\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(features)\n",
    "        loss = criterion(logits, targets.long())  # Assuming targets are class indices\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear gradients from the previous step\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        # Logging\n",
    "        if not batch_idx % 50:\n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} | '\n",
    "                  f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                  f'Loss: {loss:.4f}')\n",
    "    \n",
    "    # Compute accuracy\n",
    "    train_accuracy = compute_accuracy(model, train_loader, device)\n",
    "    valid_accuracy = compute_accuracy(model, valid_loader, device)\n",
    "    print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}\\n'\n",
    "          f'Train Accuracy: {train_accuracy:.2f}% | '\n",
    "          f'Validation Accuracy: {valid_accuracy:.2f}%')\n",
    "\n",
    "    # Save model if you want to keep checkpoints\n",
    "    # torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')\n",
    "\n",
    "elapsed_time = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed_time:.2f} min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTorchCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=13824, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
